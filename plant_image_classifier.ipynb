{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"D:/plant image classification/plant-classsification/train/10010617/0ba000d7dd2aba6050340b26c585bf665a68a5f3.jpg\") #path of your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "image_resized=cv2.resize(image,(224,224))\n",
    "image=np.expand_dims(image_resized,axis=0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is in .daa format so do extract it first\n",
    "resnet_model=load_model('D:\\plant image classification\\plant_classification.h5') #path to the image classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[[9.94702399e-01 7.71033815e-09 7.81557458e-11 8.58144666e-09\n",
      "  3.60228121e-03 2.81512480e-10 3.51060118e-11 1.61241509e-09\n",
      "  1.35440704e-12 2.50088138e-04 8.18623155e-11 1.16864626e-11\n",
      "  1.85342174e-07 5.21491245e-07 7.88180488e-14 2.35541247e-05\n",
      "  8.61755552e-07 4.11455176e-06 3.03065573e-10 2.19745083e-16\n",
      "  2.42822686e-08 4.14729279e-10 4.05148137e-11 1.24081693e-04\n",
      "  3.13169900e-14 6.62753497e-09 5.81080926e-08 2.02420211e-04\n",
      "  1.72633189e-13 9.33563970e-15 1.41124182e-10 8.75808109e-05\n",
      "  3.65280037e-08 3.80771219e-08 1.35567148e-11 1.01380606e-16\n",
      "  2.13329831e-12 2.61037570e-07 1.15001443e-04 8.42705419e-11\n",
      "  1.87132462e-11 6.58381238e-10 7.38393721e-13 1.30758437e-07\n",
      "  2.01052078e-10 6.62994659e-10 8.52244331e-10 2.09392037e-09\n",
      "  8.09356570e-04 2.17404775e-11 2.70717436e-07 1.21063488e-08\n",
      "  2.62105232e-07 2.81440116e-09 8.81006031e-07 9.97508066e-13\n",
      "  1.29127181e-10 2.26812822e-11 7.55030705e-10 1.91354807e-10\n",
      "  2.93367151e-14 6.05004274e-13 2.94487809e-14 5.17233513e-11\n",
      "  7.47682272e-09 3.78046552e-12 5.06990422e-11 3.23563502e-11\n",
      "  7.68781035e-13 6.73853117e-13 9.52223543e-12 5.47858335e-14\n",
      "  5.90796162e-11 1.65998985e-11 5.24859155e-14 8.33726546e-08\n",
      "  1.20721169e-10 1.71963539e-12 1.13682128e-17 9.95273829e-12\n",
      "  5.55332215e-14 4.64542887e-14 8.23435694e-14 2.34290976e-10\n",
      "  2.43691600e-09 2.30811693e-07 2.27371125e-11 4.92192430e-06\n",
      "  6.96967983e-10 3.16434843e-08 3.13213286e-06 5.63555980e-10\n",
      "  1.97562786e-10 5.27797241e-15 1.27821866e-13 8.49432737e-08\n",
      "  1.22813836e-12 4.34638124e-11 4.48373375e-15 3.65820167e-13\n",
      "  3.00233160e-06 1.23334806e-11 6.09877329e-13 1.12291358e-08\n",
      "  1.82567974e-14 7.44281303e-10 1.31641784e-07 8.62618310e-12\n",
      "  4.46096937e-10 2.96373575e-08 1.19247153e-14 2.07920087e-11\n",
      "  6.30876893e-05 8.97126232e-13 4.99193311e-14 2.03158184e-08\n",
      "  5.25258552e-11 2.94905959e-07 6.64951969e-08 2.91773159e-12\n",
      "  9.47299314e-13 1.42407787e-13 3.02011993e-09 5.27826532e-11\n",
      "  5.33922879e-08 6.44710188e-11 2.37531239e-09 1.72347736e-08\n",
      "  7.84292076e-10 5.98278344e-14 3.95093195e-07]]\n"
     ]
    }
   ],
   "source": [
    "preds=resnet_model.predict(image)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted class is 10010617\n"
     ]
    }
   ],
   "source": [
    "train_path='D:/plant image classification/plant-classsification/test'\n",
    "classes_plant = os.listdir(train_path)\n",
    "output_classes=classes_plant[np.argmax(preds)]\n",
    "print(f'the predicted class is {output_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
